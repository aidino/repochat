#!/usr/bin/env python3
"""
Manual Test for Task 3.5: LLMAnalysisSupportModule

Test tr·ª±c ti·∫øp LLMAnalysisSupportModule ƒë·ªÉ verify DoD compliance,
ho√†n to√†n isolated kh√¥ng import t·ª´ __init__.py.
"""

import sys
import os

# Add backend to path  
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Import tr·ª±c ti·∫øp t·ª´ modules
try:
    from src.teams.llm_services.models import (
        LLMServiceRequest, LLMServiceResponse, LLMConfig,
        LLMProviderType, LLMServiceStatus
    )
    print("‚úÖ LLM Services models imported successfully")
except ImportError as e:
    print(f"‚ùå Failed to import LLM Services models: {e}")
    sys.exit(1)

try:
    from src.teams.code_analysis.llm_analysis_support_module_minimal import (
        LLMAnalysisSupportModule, 
        CodeAnalysisContext
    )
    print("‚úÖ LLMAnalysisSupportModule (minimal) imported successfully")
except ImportError as e:
    print(f"‚ùå Failed to import LLMAnalysisSupportModule: {e}")
    sys.exit(1)


def test_task_3_5_dod_compliance():
    """Test Task 3.5 DoD compliance manually."""
    print("\n" + "=" * 70)
    print("  TASK 3.5 DoD COMPLIANCE TEST")
    print("=" * 70)
    
    test_code = """def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)"""
    
    print(f"Test Code ({len(test_code)} chars):")
    print(f"```python\n{test_code}\n```\n")
    
    # Test 1: LLMServiceRequest structure exists
    print("üìã DoD Test 1: LLMServiceRequest structure exists")
    try:
        module = LLMAnalysisSupportModule()
        request = module.create_explain_code_request(test_code)
        
        # Check structure
        assert hasattr(request, 'prompt_id'), "Missing prompt_id field"
        assert hasattr(request, 'context_data'), "Missing context_data field"
        assert hasattr(request, 'llm_config'), "Missing llm_config field"
        assert hasattr(request, 'prompt_text'), "Missing prompt_text field"
        
        print("   ‚úÖ LLMServiceRequest has all required fields")
        print(f"   üìù Fields: prompt_id={request.prompt_id}, context_data keys={list(request.context_data.keys())}")
        
    except Exception as e:
        print(f"   ‚ùå Failed: {e}")
        return False
    
    # Test 2: LLMServiceResponse structure exists  
    print("\nüìã DoD Test 2: LLMServiceResponse structure exists")
    try:
        response = LLMServiceResponse(
            response_text="Test response",
            status=LLMServiceStatus.SUCCESS
        )
        
        # Check structure
        assert hasattr(response, 'response_text'), "Missing response_text field"
        assert hasattr(response, 'status'), "Missing status field"
        
        print("   ‚úÖ LLMServiceResponse has all required fields")
        print(f"   üìù Fields: response_text='{response.response_text}', status={response.status}")
        
    except Exception as e:
        print(f"   ‚ùå Failed: {e}")
        return False
    
    # Test 3: Module c√≥ function nh·∫≠n code string
    print("\nüìã DoD Test 3: Module accepts code string")
    try:
        module = LLMAnalysisSupportModule()
        assert hasattr(module, 'create_explain_code_request'), "Missing create_explain_code_request method"
        
        request = module.create_explain_code_request(test_code)
        assert request is not None, "Method returned None"
        
        print("   ‚úÖ Module accepts code string and returns result")
        print(f"   üìù Method: create_explain_code_request exists and works")
        
    except Exception as e:
        print(f"   ‚ùå Failed: {e}")
        return False
    
    # Test 4: Function t·∫°o LLMServiceRequest v·ªõi prompt_id="explain_code"
    print("\nüìã DoD Test 4: Creates LLMServiceRequest with prompt_id='explain_code'")
    try:
        module = LLMAnalysisSupportModule()
        request = module.create_explain_code_request(test_code)
        
        assert isinstance(request, LLMServiceRequest), f"Wrong return type: {type(request)}"
        assert request.prompt_id == "explain_code", f"Wrong prompt_id: {request.prompt_id}"
        assert "code_snippet" in request.context_data, "Missing code_snippet in context_data"
        assert request.context_data["code_snippet"] == test_code, "Wrong code_snippet value"
        
        print("   ‚úÖ Creates correct LLMServiceRequest")
        print(f"   üìù prompt_id='{request.prompt_id}', code_snippet length={len(request.context_data['code_snippet'])}")
        
    except Exception as e:
        print(f"   ‚ùå Failed: {e}")
        return False
    
    # Test 5: Function s·ª≠ d·ª•ng c·∫•u h√¨nh LLM m·∫∑c ƒë·ªãnh
    print("\nüìã DoD Test 5: Uses default LLM configuration")
    try:
        module = LLMAnalysisSupportModule()
        request = module.create_explain_code_request(test_code)
        
        assert isinstance(request.llm_config, LLMConfig), f"Wrong llm_config type: {type(request.llm_config)}"
        assert request.llm_config.provider == LLMProviderType.OPENAI, f"Wrong provider: {request.llm_config.provider}"
        assert request.llm_config.model == "gpt-3.5-turbo", f"Wrong model: {request.llm_config.model}"
        
        print("   ‚úÖ Uses correct default LLM configuration")
        print(f"   üìù Provider: {request.llm_config.provider.value}, Model: {request.llm_config.model}")
        
    except Exception as e:
        print(f"   ‚ùå Failed: {e}")
        return False
    
    # Test 6: Function tr·∫£ v·ªÅ LLMServiceRequest
    print("\nüìã DoD Test 6: Returns LLMServiceRequest object")
    try:
        module = LLMAnalysisSupportModule()
        request = module.create_explain_code_request(test_code)
        
        assert isinstance(request, LLMServiceRequest), f"Wrong return type: {type(request)}"
        assert request is not None, "Returned None"
        
        print("   ‚úÖ Returns correct LLMServiceRequest object")
        print(f"   üìù Type: {type(request).__name__}, Not None: {request is not None}")
        
    except Exception as e:
        print(f"   ‚ùå Failed: {e}")
        return False
    
    return True


def test_additional_functionality():
    """Test additional functionality beyond DoD."""
    print("\n" + "=" * 70)
    print("  ADDITIONAL FUNCTIONALITY TEST")
    print("=" * 70)
    
    module = LLMAnalysisSupportModule()
    
    # Test multiple analysis types
    print("üåü Testing multiple analysis types...")
    
    test_code = "def add(a, b): return a + b"
    
    # Test analyze_function
    try:
        request = module.create_analyze_function_request(
            function_name="add",
            function_code=test_code
        )
        assert request.prompt_id == "analyze_function"
        print("   ‚úÖ analyze_function request works")
    except Exception as e:
        print(f"   ‚ùå analyze_function failed: {e}")
    
    # Test find_issues
    try:
        request = module.create_find_issues_request(
            code_content=test_code,
            file_path="test.py"
        )
        assert request.prompt_id == "find_issues"
        print("   ‚úÖ find_issues request works")
    except Exception as e:
        print(f"   ‚ùå find_issues failed: {e}")
    
    # Test CodeAnalysisContext
    try:
        context = module.create_context_from_code(
            code_snippet=test_code,
            analysis_type="explain_code"
        )
        assert isinstance(context, CodeAnalysisContext)
        assert context.code_snippet == test_code
        print("   ‚úÖ CodeAnalysisContext creation works")
    except Exception as e:
        print(f"   ‚ùå CodeAnalysisContext failed: {e}")


def demonstrate_usage():
    """Demonstrate typical usage of LLMAnalysisSupportModule."""
    print("\n" + "=" * 70)
    print("  USAGE DEMONSTRATION")
    print("=" * 70)
    
    # Sample code ƒë·ªÉ analyze
    sample_code = """def quicksort(arr):
    if len(arr) <= 1:
        return arr
    pivot = arr[len(arr) // 2]
    left = [x for x in arr if x < pivot]
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x > pivot]
    return quicksort(left) + middle + quicksort(right)"""
    
    print("üìù Sample Code for Analysis:")
    print(f"```python\n{sample_code}\n```")
    
    module = LLMAnalysisSupportModule()
    
    # Create explain_code request
    print("\nüîç Creating explain_code request...")
    request = module.create_explain_code_request(sample_code, "python")
    
    print(f"üìã Request Details:")
    print(f"   - Type: {type(request).__name__}")
    print(f"   - Prompt ID: {request.prompt_id}")
    print(f"   - Context Data Keys: {list(request.context_data.keys())}")
    print(f"   - Language: {request.context_data.get('language', 'N/A')}")
    print(f"   - LLM Provider: {request.llm_config.provider.value}")
    print(f"   - LLM Model: {request.llm_config.model}")
    print(f"   - User ID: {request.user_id}")
    print(f"   - Request ID: {request.request_id}")
    
    print("\n‚ú® This request is ready to send to TEAM LLM Services!")


def main():
    """Main test runner."""
    print("üöÄ Testing Task 3.5: LLMAnalysisSupportModule")
    print("üéØ Goal: Verify DoD compliance for Code Analysis LLM bridge")
    
    # Run DoD compliance tests
    success = test_task_3_5_dod_compliance()
    
    if success:
        print("\nüéâ ALL DoD REQUIREMENTS PASSED!")
        print("\n‚úÖ Task 3.5 Summary:")
        print("  1. ‚úÖ LLMServiceRequest/Response structures exist")
        print("  2. ‚úÖ LLMAnalysisSupportModule implemented")
        print("  3. ‚úÖ Module accepts code string")
        print("  4. ‚úÖ Creates explain_code requests correctly")
        print("  5. ‚úÖ Uses default LLM configuration")
        print("  6. ‚úÖ Returns LLMServiceRequest objects")
        
        # Test additional functionality
        test_additional_functionality()
        
        # Demonstrate usage
        demonstrate_usage()
        
        print("\nüöÄ Task 3.5 COMPLETED SUCCESSFULLY!")
        print("üîó Ready for Task 3.6: Orchestrator Agent LLM routing")
        
    else:
        print("\n‚ùå DoD requirements not fully met")
        return False
    
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 