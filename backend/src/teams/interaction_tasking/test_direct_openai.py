#!/usr/bin/env python3
"""
Test tr·ª±c ti·∫øp v·ªõi OpenAI provider ƒë·ªÉ tr√°nh dependency issues
"""

import sys
import os
import json
import re
from enum import Enum
from dataclasses import dataclass
from typing import Dict, Any, List

# Add path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

class IntentType(Enum):
    """C√°c lo·∫°i √Ω ƒë·ªãnh ng∆∞·ªùi d√πng c√≥ th·ªÉ c√≥"""
    SCAN_PROJECT = "scan_project"
    REVIEW_PR = "review_pr"
    ASK_QUESTION = "ask_question"
    REQUEST_DIAGRAM = "request_diagram"
    CONFIGURE_SETTINGS = "configure_settings"
    UNKNOWN = "unknown"
    GREETING = "greeting"
    HELP = "help"

@dataclass
class UserIntent:
    """Th√¥ng tin √Ω ƒë·ªãnh ƒë√£ ƒë∆∞·ª£c ph√¢n t√≠ch"""
    intent_type: IntentType
    confidence: float
    extracted_entities: Dict[str, Any]
    missing_information: List[str]
    suggested_questions: List[str]
    original_text: str

def test_direct_openai_approach():
    """Test direct OpenAI approach"""
    
    print("=== TEST DIRECT OPENAI APPROACH ===\n")
    
    # System prompt
    system_prompt = """B·∫°n l√† AI Assistant chuy√™n nghi·ªáp ph√¢n t√≠ch √Ω ƒë·ªãnh ng∆∞·ªùi d√πng cho RepoChat - h·ªá th·ªëng review code t·ª± ƒë·ªông b·∫±ng ti·∫øng Vi·ªát.

## NHI·ªÜM V·ª§ C·ªêT L√ïI
Ph√¢n t√≠ch ch√≠nh x√°c √Ω ƒë·ªãnh ng∆∞·ªùi d√πng v√† ƒë∆∞a ra response ph√π h·ª£p theo ng·ªØ c·∫£nh conversation t·ª± nhi√™n.

## PH√ÇN LO·∫†I √ù ƒê·ªäNH

### 1. SCAN_PROJECT (Qu√©t to√†n b·ªô d·ª± √°n)
**M√¥ t·∫£**: Ng∆∞·ªùi d√πng mu·ªën review/ph√¢n t√≠ch to√†n b·ªô source code c·ªßa m·ªôt d·ª± √°n
**Keywords**: "review code", "review d·ª± √°n", "ph√¢n t√≠ch project", "qu√©t source code", "review to√†n b·ªô"
**V√≠ d·ª• user input**: 
- "t√¥i mu·ªën review code c·ªßa d·ª± √°n"
- "review to√†n b·ªô source code"
- "ph√¢n t√≠ch d·ª± √°n n√†y"

**Response chu·∫©n khi thi·∫øu GitHub URL**:
"Ch√†o b·∫°n! source code c·ªßa b·∫°n ƒë∆∞·ª£c l∆∞a ·ªü ƒë√¢u, hi·ªán nay ch√∫ng t√¥i ch·ªâ c√≥ ch·ª©c nƒÉng review code t·∫°i github repository"

### 2. REVIEW_PR (Review Pull Request c·ª• th·ªÉ)  
**M√¥ t·∫£**: Ng∆∞·ªùi d√πng mu·ªën review m·ªôt Pull Request c·ª• th·ªÉ (PH·∫¢I c√≥ PR ID/s·ªë)
**Keywords**: "PR #123", "pull request 456", "review PR"
**Response chu·∫©n**:
"ƒê·ªÉ review Pull Request, vui l√≤ng cung c·∫•p:
‚Ä¢ URL repository
‚Ä¢ ID ho·∫∑c URL c·ªßa Pull Request

V√≠ d·ª•: Review PR #123 trong repository https://github.com/user/repo"

## QUY T·∫ÆC PH√ÇN T√çCH QUAN TR·ªåNG

1. **∆Øu ti√™n SCAN_PROJECT**: N·∫øu user n√≥i v·ªÅ "review code" m√† KH√îNG ƒë·ªÅ c·∫≠p PR c·ª• th·ªÉ ‚Üí ch·ªçn scan_project
2. **Ch·ªâ ch·ªçn REVIEW_PR**: Khi c√≥ ƒë·ªÅ c·∫≠p R√ï R√ÄNG PR ID, s·ªë PR, ho·∫∑c "pull request" v·ªõi s·ªë
3. **Response t·ª± nhi√™n**: ƒê∆∞a ra c√¢u tr·∫£ l·ªùi conversation nh∆∞ con ng∆∞·ªùi, kh√¥ng ph·∫£i JSON
4. **Ti·∫øng Vi·ªát thu·∫ßn t√∫y**: T·∫•t c·∫£ response ph·∫£i b·∫±ng ti·∫øng Vi·ªát t·ª± nhi√™n

## FORMAT TR·∫¢ L·ªúI Y√äU C·∫¶U
Tr·∫£ l·ªùi JSON v·ªõi c·∫•u tr√∫c:
{
    "intent_type": "scan_project|review_pr|ask_question|request_diagram|configure_settings|greeting|help|unknown",
    "confidence": 0.95,
    "extracted_entities": {
        "github_url": "URL n·∫øu c√≥",
        "pr_identifier": "PR ID n·∫øu c√≥", 
        "project_name": "t√™n project n·∫øu c√≥"
    },
    "missing_information": ["github_url"],
    "suggested_questions": ["Response t·ª± nhi√™n b·∫±ng ti·∫øng Vi·ªát theo template tr√™n"]
}

## EXAMPLES

Input: "t√¥i mu·ªën review code c·ªßa d·ª± √°n"
‚Üí intent_type: "scan_project"
‚Üí suggested_questions: ["Ch√†o b·∫°n! source code c·ªßa b·∫°n ƒë∆∞·ª£c l∆∞a ·ªü ƒë√¢u, hi·ªán nay ch√∫ng t√¥i ch·ªâ c√≥ ch·ª©c nƒÉng review code t·∫°i github repository"]

Input: "review PR #123"  
‚Üí intent_type: "review_pr"
‚Üí suggested_questions: ["ƒê·ªÉ review Pull Request, vui l√≤ng cung c·∫•p:\n‚Ä¢ URL repository\n‚Ä¢ ID ho·∫∑c URL c·ªßa Pull Request\n\nV√≠ d·ª•: Review PR #123 trong repository https://github.com/user/repo"]"""

    # Test v·ªõi mock OpenAI response (gi·∫£ l·∫≠p khi kh√¥ng c√≥ API key)
    def mock_openai_parse(user_text: str) -> UserIntent:
        """Mock OpenAI parsing v·ªõi logic t·ªët"""
        
        text_lower = user_text.lower()
        
        # Logic gi·ªëng LLM
        if any(word in text_lower for word in ['review code', 'review d·ª± √°n', 'ph√¢n t√≠ch d·ª± √°n', 'review to√†n b·ªô']):
            return UserIntent(
                intent_type=IntentType.SCAN_PROJECT,
                confidence=0.95,
                extracted_entities={},
                missing_information=["github_url"],
                suggested_questions=["Ch√†o b·∫°n! source code c·ªßa b·∫°n ƒë∆∞·ª£c l∆∞a ·ªü ƒë√¢u, hi·ªán nay ch√∫ng t√¥i ch·ªâ c√≥ ch·ª©c nƒÉng review code t·∫°i github repository"],
                original_text=user_text
            )
        elif any(pattern in text_lower for pattern in ['pr #', 'pull request #', 'review pr']) or re.search(r'pull request \d+|pr \d+', text_lower):
            return UserIntent(
                intent_type=IntentType.REVIEW_PR,
                confidence=0.95,
                extracted_entities={},
                missing_information=["github_url", "pr_identifier"],
                suggested_questions=["ƒê·ªÉ review Pull Request, vui l√≤ng cung c·∫•p:\n‚Ä¢ URL repository\n‚Ä¢ ID ho·∫∑c URL c·ªßa Pull Request\n\nV√≠ d·ª•: Review PR #123 trong repository https://github.com/user/repo"],
                original_text=user_text
            )
        else:
            return UserIntent(
                intent_type=IntentType.UNKNOWN,
                confidence=0.5,
                extracted_entities={},
                missing_information=[],
                suggested_questions=["B·∫°n c√≥ th·ªÉ n√≥i r√µ h∆°n v·ªÅ ƒëi·ªÅu b·∫°n mu·ªën l√†m kh√¥ng?"],
                original_text=user_text
            )
    
    # Test cases
    test_cases = [
        {
            "input": "t√¥i mu·ªën review code c·ªßa d·ª± √°n",
            "expected_intent": "scan_project",
            "expected_response": "Ch√†o b·∫°n! source code c·ªßa b·∫°n ƒë∆∞·ª£c l∆∞a ·ªü ƒë√¢u, hi·ªán nay ch√∫ng t√¥i ch·ªâ c√≥ ch·ª©c nƒÉng review code t·∫°i github repository"
        },
        {
            "input": "review to√†n b·ªô source code c·ªßa project",
            "expected_intent": "scan_project", 
            "expected_response": "Ch√†o b·∫°n! source code c·ªßa b·∫°n ƒë∆∞·ª£c l∆∞a ·ªü ƒë√¢u, hi·ªán nay ch√∫ng t√¥i ch·ªâ c√≥ ch·ª©c nƒÉng review code t·∫°i github repository"
        },
        {
            "input": "review PR #123",
            "expected_intent": "review_pr",
            "expected_response_contains": "Pull Request"
        },
        {
            "input": "xem pull request 456",
            "expected_intent": "review_pr",
            "expected_response_contains": "URL repository"
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nüîç Test Case {i}: '{test_case['input']}'")
        
        # Mock parsing
        intent = mock_openai_parse(test_case['input'])
        
        print(f"  Intent Type: {intent.intent_type.value}")
        print(f"  Confidence: {intent.confidence}")
        print(f"  Response: {intent.suggested_questions[0] if intent.suggested_questions else 'None'}")
        
        # Validate
        intent_correct = intent.intent_type.value == test_case['expected_intent']
        
        response_correct = False
        if intent.suggested_questions:
            response = intent.suggested_questions[0]
            if 'expected_response' in test_case:
                response_correct = response == test_case['expected_response']
            elif 'expected_response_contains' in test_case:
                response_correct = test_case['expected_response_contains'] in response
        
        if intent_correct and response_correct:
            print(f"  ‚úÖ SUCCESS: Perfect match!")
        elif intent_correct:
            print(f"  ‚ö†Ô∏è PARTIAL: Intent correct, response needs adjustment")
        else:
            print(f"  ‚ùå FAILED: Wrong intent. Expected: {test_case['expected_intent']}, Got: {intent.intent_type.value}")
        
        print("-" * 60)
    
    # Specialized test cho user scenario
    print(f"\nüéØ USER SCENARIO TEST:")
    user_input = "t√¥i mu·ªën review code c·ªßa d·ª± √°n"
    print(f"Input: '{user_input}'")
    
    intent = mock_openai_parse(user_input)
    expected_response = "Ch√†o b·∫°n! source code c·ªßa b·∫°n ƒë∆∞·ª£c l∆∞a ·ªü ƒë√¢u, hi·ªán nay ch√∫ng t√¥i ch·ªâ c√≥ ch·ª©c nƒÉng review code t·∫°i github repository"
    
    print(f"Intent: {intent.intent_type.value}")
    if intent.suggested_questions:
        actual_response = intent.suggested_questions[0]
        print(f"Response: {actual_response}")
        
        if actual_response == expected_response:
            print("‚úÖ PERFECT MATCH: Exact response as required!")
        else:
            print("‚ùå MISMATCH: Response different from requirement")

if __name__ == "__main__":
    test_direct_openai_approach() 